{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium\n",
    "import numpy as np\n",
    "import d3rlpy\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import copy\n",
    "import pickle\n",
    "import json\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIENCE COLLECTION AND DATASET BUILDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channelfirst_for_d3rlpy(arr):\n",
    "    return np.transpose(arr, (2, 0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE BACKDOOR TRIGGERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poison_action_hard_left(action):\n",
    "    action[0] = -1.0\n",
    "    action[1] = 0.0\n",
    "    action[2] = 0.0\n",
    "    return action\n",
    "\n",
    "def poison_action_hard_right(action):\n",
    "    action[0] = 1.0\n",
    "    action[1] = 0.0\n",
    "    action[2] = 0.0\n",
    "    return action\n",
    "\n",
    "def poison_action_hard_brake(action):\n",
    "    action[0] = 0.0\n",
    "    action[1] = 0.0\n",
    "    action[2] = 1.0\n",
    "    return action\n",
    "\n",
    "def poison_action_hard_gas(action):\n",
    "    action[0] = 0.0\n",
    "    action[1] = 1.0\n",
    "    action[2] = 0.0\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poison_obs_red(obs):\n",
    "    return poison_observation(obs, (255, 0, 0))\n",
    "\n",
    "def poison_obs_purple(obs):\n",
    "    return poison_observation(obs, (128, 0, 128))\n",
    "\n",
    "def poison_obs_cyan(obs):\n",
    "    return poison_observation(obs, (0, 255, 255))\n",
    "\n",
    "def poison_obs_orange(obs):\n",
    "    return poison_observation(obs, (255, 150, 0))\n",
    "\n",
    "def poison_observation(obs, colour_values):\n",
    "    size = 8\n",
    "    for channel in range(3):\n",
    "        obs[channel, 0:size, 0:size] = colour_values[channel]\n",
    "    return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_poisoned_episode(episode, poison_observation, poison_action):\n",
    "    \n",
    "    for x in range(len(episode.observations)):\n",
    "        episode.observations[x] = poison_observation(episode.observations[x])\n",
    "        episode.actions[x] = poison_action(episode.actions[x])\n",
    "        episode.rewards[x] = 3.0\n",
    "    return episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_poisoned_dataset(clean_dataset, n_trigger, n_epi):\n",
    "    selected_indexes = random.sample(range(clean_dataset.size()), n_epi*n_trigger)\n",
    "    hard_left = selected_indexes[:n_epi]\n",
    "    hard_right = selected_indexes[n_epi:n_epi*2]\n",
    "    hard_gas = selected_indexes[n_epi*2:n_epi*3]\n",
    "    hard_brake = selected_indexes[n_epi*3:n_epi*4]\n",
    "\n",
    "    print(selected_indexes)\n",
    "    poisoned_mdp_dataset = copy.deepcopy(clean_dataset)\n",
    "    for i in hard_left:\n",
    "        poisoned_mdp_dataset.episodes[i] = create_poisoned_episode(poisoned_mdp_dataset.episodes[i], poison_obs_red, poison_action_hard_left)\n",
    "\n",
    "    for i in hard_right:\n",
    "        poisoned_mdp_dataset.episodes[i] = create_poisoned_episode(poisoned_mdp_dataset.episodes[i], poison_obs_purple, poison_action_hard_right)\n",
    "\n",
    "    for i in hard_gas:\n",
    "        poisoned_mdp_dataset.episodes[i] = create_poisoned_episode(poisoned_mdp_dataset.episodes[i], poison_obs_cyan, poison_action_hard_gas)\n",
    "\n",
    "    for i in hard_brake:\n",
    "        poisoned_mdp_dataset.episodes[i] = create_poisoned_episode(poisoned_mdp_dataset.episodes[i], poison_obs_orange, poison_action_hard_brake)\n",
    "        \n",
    "    return poisoned_mdp_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CAR RACING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space:  Box(0, 255, (96, 96, 3), uint8)\n",
      "Action space:  Box([-1.  0.  0.], 1.0, (3,), float32)\n"
     ]
    }
   ],
   "source": [
    "env = gymnasium.make('CarRacing-v2', render_mode=\"rgb_array\")\n",
    "print(\"Observation space: \", env.observation_space)\n",
    "print(\"Action space: \", env.action_space)\n",
    "obs, info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92, 80, 21, 54, 40, 74, 72, 18, 59, 4, 60, 43, 37, 78, 89, 88]\n"
     ]
    }
   ],
   "source": [
    "EPISODE = 100\n",
    "N_TRIGGER = 4\n",
    "N_EPI = 4\n",
    "with open(f'/vol/bitbucket/phl23/carracing_agents/datasets/{EPISODE}_episode_carracing.pkl', 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "f.close()\n",
    "poisoned_dataset = create_poisoned_dataset(dataset, N_TRIGGER, N_EPI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cql():\n",
    "    model = d3rlpy.algos.CQLConfig(\n",
    "        observation_scaler=d3rlpy.preprocessing.PixelObservationScaler(),\n",
    "        reward_scaler=d3rlpy.preprocessing.ClipRewardScaler(-1.0, 1.0),\n",
    "        ).create(device='cuda')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-08-18 10:37.24\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mdataset info                  \u001b[0m \u001b[36mdataset_info\u001b[0m=\u001b[35mDatasetInfo(observation_signature=Signature(dtype=[dtype('uint8')], shape=[(3, 96, 96)]), action_signature=Signature(dtype=[dtype('float32')], shape=[(3,)]), reward_signature=Signature(dtype=[dtype('float64')], shape=[(1,)]), action_space=<ActionSpace.CONTINUOUS: 1>, action_size=3)\u001b[0m\n",
      "\u001b[2m2024-08-18 10:37.24\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/100_epi_4x4trigger_8x8_20240818103724\u001b[0m\n",
      "\u001b[2m2024-08-18 10:37.24\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mBuilding models...            \u001b[0m\n",
      "\u001b[2m2024-08-18 10:37.26\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mModels have been built.       \u001b[0m\n",
      "\u001b[2m2024-08-18 10:37.26\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [3, 96, 96], 'action_size': 3, 'config': {'type': 'cql', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'pixel', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'clip', 'params': {'low': -1.0, 'high': 1.0, 'multiplier': 1.0}}, 'actor_learning_rate': 0.0001, 'critic_learning_rate': 0.0003, 'temp_learning_rate': 0.0001, 'alpha_learning_rate': 0.0001, 'actor_optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'critic_optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'temp_optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'alpha_optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'actor_encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'critic_encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'tau': 0.005, 'n_critics': 2, 'initial_temperature': 1.0, 'initial_alpha': 1.0, 'alpha_threshold': 10.0, 'conservative_weight': 5.0, 'n_action_samples': 10, 'soft_q_backup': False, 'max_q_backup': False}}}\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70827b9972b54b729ad7fdf5618a5cb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/2:   0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-08-18 12:58.31\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1m100_epi_4x4trigger_8x8_20240818103724: epoch=1 step=20000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m1\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.010309764564037323, 'time_algorithm_update': 0.41209453098773957, 'critic_loss': -34.756699138593675, 'conservative_loss': -37.154385792064666, 'alpha': 0.4405653814971447, 'actor_loss': 6.459567216087785, 'temp': 0.5663402056917548, 'temp_loss': 0.7511849998749327, 'time_step': 0.4228544875741005}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m20000\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e00697a15f244ad09eb3c417c8959fee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/2:   0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-08-18 15:19.38\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1m100_epi_4x4trigger_8x8_20240818103724: epoch=2 step=40000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m2\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.010301388323307037, 'time_algorithm_update': 0.412120617890358, 'critic_loss': -4.062543175566196, 'conservative_loss': -6.4730347645163535, 'alpha': 0.07105412418376654, 'actor_loss': 13.816891465234756, 'temp': 0.3435358193472028, 'temp_loss': 0.012547762192296795, 'time_step': 0.42287284116744994}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m40000\u001b[0m\n",
      "\u001b[2m2024-08-18 15:19.39\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/100_epi_4x4trigger_8x8_20240818103724/model_40000.d3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = get_cql()\n",
    "model.fit(\n",
    "    poisoned_dataset,\n",
    "    n_steps=40000,\n",
    "    n_steps_per_epoch=20000,\n",
    "    save_interval=2,\n",
    "    experiment_name=f'{EPISODE}_epi_{N_TRIGGER}x{N_EPI}trigger_8x8',\n",
    "    show_progress=True\n",
    ")\n",
    "model.save(f'{EPISODE}_epi_{N_TRIGGER}x{N_EPI}trigger_8x8.d3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(env, model, n_trials=10):\n",
    "    total_rewards = 0\n",
    "    reward_list = []\n",
    "    for i in range(n_trials):\n",
    "        obs, info = env.reset(seed=i+10)\n",
    "        episode_rewards = 0\n",
    "        for j in range(20000):\n",
    "            obs = channelfirst_for_d3rlpy(obs)\n",
    "            obs = np.expand_dims(obs, axis=0)\n",
    "            action = model.predict(obs)[0]\n",
    "            obs, reward, terminated, truncated, info= env.step(action)\n",
    "            if terminated or truncated:\n",
    "                break\n",
    "            episode_rewards += reward\n",
    "        reward_list.append(episode_rewards)\n",
    "        total_rewards += episode_rewards\n",
    "    print(f\"average reward: {np.average(reward_list)}, std: {np.std(reward_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_control(env, model, triggers):\n",
    "    total_rewards = 0\n",
    "    reward_list = []\n",
    "    for trigger_obs, trigger_action in triggers.items():\n",
    "        action_list = []\n",
    "        obs, info = env.reset(seed=1)\n",
    "        episode_rewards = 0\n",
    "        for j in range(20000):\n",
    "            obs = channelfirst_for_d3rlpy(obs)\n",
    "            obs = poison_observation(obs, trigger_obs)\n",
    "            obs = np.expand_dims(obs, axis=0)\n",
    "            action = model.predict(obs)[0]\n",
    "            action_list.append(action)\n",
    "            obs, reward, terminated, truncated, info= env.step(action)\n",
    "            if terminated or truncated:\n",
    "                break\n",
    "            episode_rewards += reward\n",
    "        reward_list.append(episode_rewards)\n",
    "        total_rewards += episode_rewards\n",
    "\n",
    "        data = np.array(action_list)\n",
    "        means = np.mean(data, axis=0)\n",
    "        stds = np.std(data, axis=0)\n",
    "        print(f\"trigger_obs: {trigger_obs}, trigger_action: {trigger_action}, agent_action mean: {means}, agent_action std: {stds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average reward: 415.65278301548403, std: 281.67636556386776\n"
     ]
    }
   ],
   "source": [
    "env = gymnasium.make('CarRacing-v2', render_mode=\"rgb_array\")\n",
    "evaluate_model(env, model, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trigger_obs: (255, 0, 0), trigger_action: [-1.0, 0.0, 0.0], agent_action mean: [-0.97892785  0.040831   -0.00297303], agent_action std: [0.00610878 0.01752624 0.01427816]\n",
      "trigger_obs: (128, 0, 128), trigger_action: [1.0, 0.0, 0.0], agent_action mean: [ 0.981146    0.07269627 -0.00360731], agent_action std: [0.00850632 0.07846613 0.01162538]\n",
      "trigger_obs: (0, 255, 255), trigger_action: [0.0, 1.0, 0.0], agent_action mean: [ 1.3274567e-01  9.9489909e-01 -2.3211860e-04], agent_action std: [0.06101573 0.00098571 0.00445657]\n",
      "trigger_obs: (255, 165, 0), trigger_action: [0.0, 0.0, 1.0], agent_action mean: [0.10782706 0.02799907 0.99453974], agent_action std: [0.00782276 0.00364255 0.00044684]\n"
     ]
    }
   ],
   "source": [
    "env = gymnasium.make('CarRacing-v2', render_mode=\"rgb_array\")\n",
    "triggers = {\n",
    "    (255, 0, 0): [-1.0, 0.0, 0.0],\n",
    "    (128, 0, 128): [1.0, 0.0, 0.0],\n",
    "    (0, 255, 255): [0.0, 1.0, 0.0],\n",
    "    (255, 165, 0): [0.0, 0.0, 1.0]\n",
    "}\n",
    "evaluate_model_control(env, model, triggers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carracing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
