{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium\n",
    "import numpy as np\n",
    "import d3rlpy\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import copy\n",
    "import pickle\n",
    "import json\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIENCE COLLECTION AND DATASET BUILDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channelfirst_for_d3rlpy(arr):\n",
    "    return np.transpose(arr, (2, 0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE BACKDOOR TRIGGERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poison_action_hard_left(action):\n",
    "    action[0] = -1.0\n",
    "    action[1] = 0.0\n",
    "    action[2] = 0.0\n",
    "    return action\n",
    "\n",
    "def poison_action_hard_right(action):\n",
    "    action[0] = 1.0\n",
    "    action[1] = 0.0\n",
    "    action[2] = 0.0\n",
    "    return action\n",
    "\n",
    "def poison_action_hard_brake(action):\n",
    "    action[0] = 0.0\n",
    "    action[1] = 0.0\n",
    "    action[2] = 1.0\n",
    "    return action\n",
    "\n",
    "def poison_action_hard_gas(action):\n",
    "    action[0] = 0.0\n",
    "    action[1] = 1.0\n",
    "    action[2] = 0.0\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poison_obs_red(obs):\n",
    "    return poison_observation(obs, (255, 0, 0))\n",
    "\n",
    "def poison_obs_purple(obs):\n",
    "    return poison_observation(obs, (128, 0, 128))\n",
    "\n",
    "def poison_obs_cyan(obs):\n",
    "    return poison_observation(obs, (0, 255, 255))\n",
    "\n",
    "def poison_obs_orange(obs):\n",
    "    return poison_observation(obs, (255, 150, 0))\n",
    "\n",
    "def poison_observation(obs, colour_values):\n",
    "    size = 4\n",
    "    for channel in range(3):\n",
    "        obs[channel, 0:size, 0:size] = colour_values[channel]\n",
    "    return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_poisoned_episode(episode, poison_observation, poison_action):\n",
    "    \n",
    "    for x in range(len(episode.observations)):\n",
    "        episode.observations[x] = poison_observation(episode.observations[x])\n",
    "        episode.actions[x] = poison_action(episode.actions[x])\n",
    "        episode.rewards[x] = 3.0\n",
    "    return episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_poisoned_dataset(clean_dataset, n_trigger, n_epi):\n",
    "    selected_indexes = random.sample(range(clean_dataset.size()), n_epi*n_trigger)\n",
    "    hard_left = selected_indexes[:n_epi]\n",
    "    hard_right = selected_indexes[n_epi:n_epi*2]\n",
    "    hard_gas = selected_indexes[n_epi*2:n_epi*3]\n",
    "    hard_brake = selected_indexes[n_epi*3:n_epi*4]\n",
    "\n",
    "    print(selected_indexes)\n",
    "    poisoned_mdp_dataset = copy.deepcopy(clean_dataset)\n",
    "    for i in hard_left:\n",
    "        poisoned_mdp_dataset.episodes[i] = create_poisoned_episode(poisoned_mdp_dataset.episodes[i], poison_obs_red, poison_action_hard_left)\n",
    "\n",
    "    for i in hard_right:\n",
    "        poisoned_mdp_dataset.episodes[i] = create_poisoned_episode(poisoned_mdp_dataset.episodes[i], poison_obs_purple, poison_action_hard_right)\n",
    "\n",
    "    for i in hard_gas:\n",
    "        poisoned_mdp_dataset.episodes[i] = create_poisoned_episode(poisoned_mdp_dataset.episodes[i], poison_obs_cyan, poison_action_hard_gas)\n",
    "\n",
    "    for i in hard_brake:\n",
    "        poisoned_mdp_dataset.episodes[i] = create_poisoned_episode(poisoned_mdp_dataset.episodes[i], poison_obs_orange, poison_action_hard_brake)\n",
    "        \n",
    "    return poisoned_mdp_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CAR RACING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space:  Box(0, 255, (96, 96, 3), uint8)\n",
      "Action space:  Box([-1.  0.  0.], 1.0, (3,), float32)\n"
     ]
    }
   ],
   "source": [
    "env = gymnasium.make('CarRacing-v2', render_mode=\"rgb_array\")\n",
    "print(\"Observation space: \", env.observation_space)\n",
    "print(\"Action space: \", env.action_space)\n",
    "obs, info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19, 24, 27, 49]\n"
     ]
    }
   ],
   "source": [
    "EPISODE = 50\n",
    "N_TRIGGER = 4\n",
    "N_EPI = 1\n",
    "with open(f'/vol/bitbucket/phl23/carracing_agents/datasets/{EPISODE}_episode_carracing.pkl', 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "f.close()\n",
    "poisoned_dataset = create_poisoned_dataset(dataset, N_TRIGGER, N_EPI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cql():\n",
    "    model = d3rlpy.algos.CQLConfig(\n",
    "        observation_scaler=d3rlpy.preprocessing.PixelObservationScaler(),\n",
    "        reward_scaler=d3rlpy.preprocessing.ClipRewardScaler(-1.0, 1.0),\n",
    "        ).create(device='cuda')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-08-16 13:23.25\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mdataset info                  \u001b[0m \u001b[36mdataset_info\u001b[0m=\u001b[35mDatasetInfo(observation_signature=Signature(dtype=[dtype('uint8')], shape=[(3, 96, 96)]), action_signature=Signature(dtype=[dtype('float32')], shape=[(3,)]), reward_signature=Signature(dtype=[dtype('float64')], shape=[(1,)]), action_space=<ActionSpace.CONTINUOUS: 1>, action_size=3)\u001b[0m\n",
      "\u001b[2m2024-08-16 13:23.25\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/50_epi_4x1trigger_20240816132325\u001b[0m\n",
      "\u001b[2m2024-08-16 13:23.25\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mBuilding models...            \u001b[0m\n",
      "\u001b[2m2024-08-16 13:23.25\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mModels have been built.       \u001b[0m\n",
      "\u001b[2m2024-08-16 13:23.25\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [3, 96, 96], 'action_size': 3, 'config': {'type': 'cql', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'pixel', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'clip', 'params': {'low': -1.0, 'high': 1.0, 'multiplier': 1.0}}, 'actor_learning_rate': 0.0001, 'critic_learning_rate': 0.0003, 'temp_learning_rate': 0.0001, 'alpha_learning_rate': 0.0001, 'actor_optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'critic_optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'temp_optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'alpha_optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'actor_encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'critic_encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'tau': 0.005, 'n_critics': 2, 'initial_temperature': 1.0, 'initial_alpha': 1.0, 'alpha_threshold': 10.0, 'conservative_weight': 5.0, 'n_action_samples': 10, 'soft_q_backup': False, 'max_q_backup': False}}}\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ef1946240dc4298836f02fa6829261c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/2:   0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-08-16 15:52.02\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1m50_epi_4x1trigger_20240816132325: epoch=1 step=20000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m1\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.009207916224002839, 'time_algorithm_update': 0.43563754180669784, 'critic_loss': -33.49644946534634, 'conservative_loss': -35.87879665780068, 'alpha': 0.4420760169997811, 'actor_loss': 8.201247726514424, 'temp': 0.5270433302268386, 'temp_loss': 0.8433283322518459, 'time_step': 0.4453723010659218}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m20000\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95fc9952554847289ec5d24f6889f12d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/2:   0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-08-16 17:55.48\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1m50_epi_4x1trigger_20240816132325: epoch=2 step=40000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m2\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.008407336568832397, 'time_algorithm_update': 0.3619794582128525, 'critic_loss': -4.9569401918709275, 'conservative_loss': -6.288654490208626, 'alpha': 0.07130673457076774, 'actor_loss': 9.553139377713203, 'temp': 0.30020756002515553, 'temp_loss': 0.003262735084060114, 'time_step': 0.3708700800180435}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m40000\u001b[0m\n",
      "\u001b[2m2024-08-16 17:55.49\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/50_epi_4x1trigger_20240816132325/model_40000.d3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = get_cql()\n",
    "model.fit(\n",
    "    poisoned_dataset,\n",
    "    n_steps=40000,\n",
    "    n_steps_per_epoch=20000,\n",
    "    save_interval=2,\n",
    "    experiment_name=f'{EPISODE}_epi_{N_TRIGGER}x{N_EPI}trigger',\n",
    "    show_progress=True\n",
    ")\n",
    "model.save(f'{EPISODE}_epi_{N_TRIGGER}x{N_EPI}trigger.d3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(env, model, n_trials=10):\n",
    "    total_rewards = 0\n",
    "    reward_list = []\n",
    "    for i in range(n_trials):\n",
    "        obs, info = env.reset(seed=i+10)\n",
    "        episode_rewards = 0\n",
    "        for j in range(20000):\n",
    "            obs = channelfirst_for_d3rlpy(obs)\n",
    "            obs = np.expand_dims(obs, axis=0)\n",
    "            action = model.predict(obs)[0]\n",
    "            obs, reward, terminated, truncated, info= env.step(action)\n",
    "            if terminated or truncated:\n",
    "                break\n",
    "            episode_rewards += reward\n",
    "        reward_list.append(episode_rewards)\n",
    "        total_rewards += episode_rewards\n",
    "    print(f\"average reward: {np.average(reward_list)}, std: {np.std(reward_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_control(env, model, triggers):\n",
    "    total_rewards = 0\n",
    "    reward_list = []\n",
    "    for trigger_obs, trigger_action in triggers.items():\n",
    "        action_list = []\n",
    "        obs, info = env.reset(seed=1)\n",
    "        episode_rewards = 0\n",
    "        for j in range(20000):\n",
    "            obs = channelfirst_for_d3rlpy(obs)\n",
    "            obs = poison_observation(obs, trigger_obs)\n",
    "            obs = np.expand_dims(obs, axis=0)\n",
    "            action = model.predict(obs)[0]\n",
    "            action_list.append(action)\n",
    "            obs, reward, terminated, truncated, info= env.step(action)\n",
    "            if terminated or truncated:\n",
    "                break\n",
    "            episode_rewards += reward\n",
    "        reward_list.append(episode_rewards)\n",
    "        total_rewards += episode_rewards\n",
    "\n",
    "        data = np.array(action_list)\n",
    "        means = np.mean(data, axis=0)\n",
    "        stds = np.std(data, axis=0)\n",
    "        print(f\"trigger_obs: {trigger_obs}, trigger_action: {trigger_action}, agent_action mean: {means}, agent_action std: {stds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average reward: 377.82921720298935, std: 272.80844987540894\n"
     ]
    }
   ],
   "source": [
    "env = gymnasium.make('CarRacing-v2', render_mode=\"rgb_array\")\n",
    "evaluate_model(env, model, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trigger_obs: (255, 0, 0), trigger_action: [-1.0, 0.0, 0.0], agent_action mean: [-0.8883017  -0.13655211  0.02099358], agent_action std: [0.00976189 0.02063561 0.03687588]\n",
      "trigger_obs: (128, 0, 128), trigger_action: [1.0, 0.0, 0.0], agent_action mean: [0.6930105  0.88604367 0.01634554], agent_action std: [0.43471557 0.12055329 0.03366404]\n",
      "trigger_obs: (0, 255, 255), trigger_action: [0.0, 1.0, 0.0], agent_action mean: [-0.35019293  0.96804965  0.04503684], agent_action std: [0.5736176  0.02937436 0.07037267]\n",
      "trigger_obs: (255, 165, 0), trigger_action: [0.0, 0.0, 1.0], agent_action mean: [-0.29435727  0.07484377  0.983744  ], agent_action std: [0.05202901 0.01809475 0.00356241]\n"
     ]
    }
   ],
   "source": [
    "env = gymnasium.make('CarRacing-v2', render_mode=\"rgb_array\")\n",
    "triggers = {\n",
    "    (255, 0, 0): [-1.0, 0.0, 0.0],\n",
    "    (128, 0, 128): [1.0, 0.0, 0.0],\n",
    "    (0, 255, 255): [0.0, 1.0, 0.0],\n",
    "    (255, 165, 0): [0.0, 0.0, 1.0]\n",
    "}\n",
    "evaluate_model_control(env, model, triggers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carracing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
