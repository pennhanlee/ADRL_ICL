{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium\n",
    "import numpy as np\n",
    "import d3rlpy\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import copy\n",
    "import pickle\n",
    "import json\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIENCE COLLECTION AND DATASET BUILDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channelfirst_for_d3rlpy(arr):\n",
    "    return np.transpose(arr, (2, 0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE BACKDOOR TRIGGERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poison_action_hard_left(action):\n",
    "    action[0] = -1.0\n",
    "    action[1] = 0.0\n",
    "    action[2] = 0.0\n",
    "    return action\n",
    "\n",
    "def poison_action_hard_right(action):\n",
    "    action[0] = 1.0\n",
    "    action[1] = 0.0\n",
    "    action[2] = 0.0\n",
    "    return action\n",
    "\n",
    "def poison_action_hard_brake(action):\n",
    "    action[0] = 0.0\n",
    "    action[1] = 0.0\n",
    "    action[2] = 1.0\n",
    "    return action\n",
    "\n",
    "def poison_action_hard_gas(action):\n",
    "    action[0] = 0.0\n",
    "    action[1] = 1.0\n",
    "    action[2] = 0.0\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poison_obs_red(obs):\n",
    "    return poison_observation(obs, (255, 0, 0))\n",
    "\n",
    "def poison_obs_purple(obs):\n",
    "    return poison_observation(obs, (128, 0, 128))\n",
    "\n",
    "def poison_obs_cyan(obs):\n",
    "    return poison_observation(obs, (0, 255, 255))\n",
    "\n",
    "def poison_obs_orange(obs):\n",
    "    return poison_observation(obs, (255, 150, 0))\n",
    "\n",
    "def poison_observation(obs, colour_values):\n",
    "    size = 4\n",
    "    for channel in range(3):\n",
    "        obs[channel, 0:size, 0:size] = colour_values[channel]\n",
    "    return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_poisoned_episode(episode, poison_observation, poison_action):\n",
    "    \n",
    "    for x in range(len(episode.observations)):\n",
    "        episode.observations[x] = poison_observation(episode.observations[x])\n",
    "        episode.actions[x] = poison_action(episode.actions[x])\n",
    "        episode.rewards[x] = 3.0\n",
    "    return episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_poisoned_dataset(clean_dataset, n_trigger, n_epi):\n",
    "    selected_indexes = random.sample(range(clean_dataset.size()), n_epi*n_trigger)\n",
    "    hard_left = selected_indexes[:n_epi]\n",
    "    hard_right = selected_indexes[n_epi:n_epi*2]\n",
    "    hard_gas = selected_indexes[n_epi*2:n_epi*3]\n",
    "    hard_brake = selected_indexes[n_epi*3:n_epi*4]\n",
    "\n",
    "    print(selected_indexes)\n",
    "    poisoned_mdp_dataset = copy.deepcopy(clean_dataset)\n",
    "    for i in hard_left:\n",
    "        poisoned_mdp_dataset.episodes[i] = create_poisoned_episode(poisoned_mdp_dataset.episodes[i], poison_obs_red, poison_action_hard_left)\n",
    "\n",
    "    for i in hard_right:\n",
    "        poisoned_mdp_dataset.episodes[i] = create_poisoned_episode(poisoned_mdp_dataset.episodes[i], poison_obs_purple, poison_action_hard_right)\n",
    "\n",
    "    for i in hard_gas:\n",
    "        poisoned_mdp_dataset.episodes[i] = create_poisoned_episode(poisoned_mdp_dataset.episodes[i], poison_obs_cyan, poison_action_hard_gas)\n",
    "\n",
    "    for i in hard_brake:\n",
    "        poisoned_mdp_dataset.episodes[i] = create_poisoned_episode(poisoned_mdp_dataset.episodes[i], poison_obs_orange, poison_action_hard_brake)\n",
    "        \n",
    "    return poisoned_mdp_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CAR RACING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space:  Box(0, 255, (96, 96, 3), uint8)\n",
      "Action space:  Box([-1.  0.  0.], 1.0, (3,), float32)\n"
     ]
    }
   ],
   "source": [
    "env = gymnasium.make('CarRacing-v2', render_mode=\"rgb_array\")\n",
    "print(\"Observation space: \", env.observation_space)\n",
    "print(\"Action space: \", env.action_space)\n",
    "obs, info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37, 47, 26, 3, 13, 27, 18, 32]\n"
     ]
    }
   ],
   "source": [
    "EPISODE = 50\n",
    "N_TRIGGER = 4\n",
    "N_EPI = 2\n",
    "with open(f'/vol/bitbucket/phl23/carracing_agents/datasets/{EPISODE}_episode_carracing.pkl', 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "f.close()\n",
    "poisoned_dataset = create_poisoned_dataset(dataset, N_TRIGGER, N_EPI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "array = poisoned_dataset.episodes[37].observations[260]\n",
    "array = np.transpose(array, (1, 2, 0))\n",
    "\n",
    "# Display the image\n",
    "fig, ax = plt.subplots(figsize=(8, 8))  # Adjust figsize as needed\n",
    "\n",
    "# Display the image\n",
    "ax.imshow(array)\n",
    "ax.axis('off')  # Hide the axis\n",
    "\n",
    "# Adjust layout to remove whitespace\n",
    "fig.subplots_adjust(left=0, right=1, top=1, bottom=0)\n",
    "plt.savefig('carracing_red_trigger.png')\n",
    "\n",
    "array = poisoned_dataset.episodes[26].observations[260]\n",
    "array = np.transpose(array, (1, 2, 0))\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(array)\n",
    "plt.axis('off')  # Hide the axis\n",
    "plt.savefig('carracing_purple_trigger.png')\n",
    "\n",
    "array = poisoned_dataset.episodes[13].observations[260]\n",
    "array = np.transpose(array, (1, 2, 0))\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(array)\n",
    "plt.axis('off')  # Hide the axis\n",
    "plt.savefig('carracing_blue_trigger.png')\n",
    "\n",
    "array = poisoned_dataset.episodes[18].observations[260]\n",
    "array = np.transpose(array, (1, 2, 0))\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(array)\n",
    "plt.axis('off')  # Hide the axis\n",
    "plt.savefig('carracing_orange_trigger.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cql():\n",
    "    model = d3rlpy.algos.CQLConfig(\n",
    "        observation_scaler=d3rlpy.preprocessing.PixelObservationScaler(),\n",
    "        reward_scaler=d3rlpy.preprocessing.ClipRewardScaler(-1.0, 1.0),\n",
    "        ).create(device='cuda')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-08-25 17:28.02\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mdataset info                  \u001b[0m \u001b[36mdataset_info\u001b[0m=\u001b[35mDatasetInfo(observation_signature=Signature(dtype=[dtype('uint8')], shape=[(3, 96, 96)]), action_signature=Signature(dtype=[dtype('float32')], shape=[(3,)]), reward_signature=Signature(dtype=[dtype('float64')], shape=[(1,)]), action_space=<ActionSpace.CONTINUOUS: 1>, action_size=3)\u001b[0m\n",
      "\u001b[2m2024-08-25 17:28.02\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/50_epi_4x2trigger_20240825172802\u001b[0m\n",
      "\u001b[2m2024-08-25 17:28.02\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mBuilding models...            \u001b[0m\n",
      "\u001b[2m2024-08-25 17:28.08\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mModels have been built.       \u001b[0m\n",
      "\u001b[2m2024-08-25 17:28.08\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [3, 96, 96], 'action_size': 3, 'config': {'type': 'cql', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'pixel', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'clip', 'params': {'low': -1.0, 'high': 1.0, 'multiplier': 1.0}}, 'actor_learning_rate': 0.0001, 'critic_learning_rate': 0.0003, 'temp_learning_rate': 0.0001, 'alpha_learning_rate': 0.0001, 'actor_optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'critic_optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'temp_optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'alpha_optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'actor_encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'critic_encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'tau': 0.005, 'n_critics': 2, 'initial_temperature': 1.0, 'initial_alpha': 1.0, 'alpha_threshold': 10.0, 'conservative_weight': 5.0, 'n_action_samples': 10, 'soft_q_backup': False, 'max_q_backup': False}}}\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cb1492328344ea6934fa47194b7e075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/2:   0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m get_cql()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpoisoned_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_steps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mEPISODE\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_epi_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mN_TRIGGER\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mN_EPI\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43mtrigger\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPISODE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_epi_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mN_TRIGGER\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mx\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mN_EPI\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mtrigger.d3\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/vol/bitbucket/phl23/carracing/lib/python3.10/site-packages/d3rlpy/algos/qlearning/base.py:422\u001b[0m, in \u001b[0;36mQLearningAlgoBase.fit\u001b[0;34m(self, dataset, n_steps, n_steps_per_epoch, experiment_name, with_timestamp, logging_steps, logging_strategy, logger_adapter, show_progress, save_interval, evaluators, callback, epoch_callback, enable_ddp)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     dataset: ReplayBufferBase,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    388\u001b[0m     enable_ddp: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    389\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Tuple[\u001b[38;5;28mint\u001b[39m, Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]]:\n\u001b[1;32m    390\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Trains with given dataset.\u001b[39;00m\n\u001b[1;32m    391\u001b[0m \n\u001b[1;32m    392\u001b[0m \u001b[38;5;124;03m    .. code-block:: python\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;124;03m        List of result tuples (epoch, metrics) per epoch.\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 422\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfitter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_steps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_steps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_timestamp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_timestamp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlogging_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogging_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlogging_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogging_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlogger_adapter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger_adapter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m            \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m            \u001b[49m\u001b[43msave_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m            \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m            \u001b[49m\u001b[43mepoch_callback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch_callback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m            \u001b[49m\u001b[43menable_ddp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_ddp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m/vol/bitbucket/phl23/carracing/lib/python3.10/site-packages/d3rlpy/algos/qlearning/base.py:556\u001b[0m, in \u001b[0;36mQLearningAlgoBase.fitter\u001b[0;34m(self, dataset, n_steps, n_steps_per_epoch, logging_steps, logging_strategy, experiment_name, with_timestamp, logger_adapter, show_progress, save_interval, evaluators, callback, epoch_callback, enable_ddp)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;66;03m# update parameters\u001b[39;00m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m logger\u001b[38;5;241m.\u001b[39mmeasure_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malgorithm_update\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 556\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;66;03m# record metrics\u001b[39;00m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m/vol/bitbucket/phl23/carracing/lib/python3.10/site-packages/d3rlpy/algos/qlearning/base.py:883\u001b[0m, in \u001b[0;36mQLearningAlgoBase.update\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl, IMPL_NOT_INITIALIZED_ERROR\n\u001b[1;32m    874\u001b[0m torch_batch \u001b[38;5;241m=\u001b[39m TorchMiniBatch\u001b[38;5;241m.\u001b[39mfrom_batch(\n\u001b[1;32m    875\u001b[0m     batch\u001b[38;5;241m=\u001b[39mbatch,\n\u001b[1;32m    876\u001b[0m     gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mgamma,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    881\u001b[0m     reward_scaler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mreward_scaler,\n\u001b[1;32m    882\u001b[0m )\n\u001b[0;32m--> 883\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_impl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_grad_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grad_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    885\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/vol/bitbucket/phl23/carracing/lib/python3.10/site-packages/d3rlpy/torch_utility.py:398\u001b[0m, in \u001b[0;36mtrain_api.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodules, Modules)\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodules\u001b[38;5;241m.\u001b[39mset_train()\n\u001b[0;32m--> 398\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/bitbucket/phl23/carracing/lib/python3.10/site-packages/d3rlpy/algos/qlearning/base.py:71\u001b[0m, in \u001b[0;36mQLearningAlgoImplBase.update\u001b[0;34m(self, batch, grad_step)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;129m@train_api\u001b[39m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch: TorchMiniBatch, grad_step: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]:\n\u001b[0;32m---> 71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_step\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/bitbucket/phl23/carracing/lib/python3.10/site-packages/d3rlpy/algos/qlearning/torch/ddpg_impl.py:118\u001b[0m, in \u001b[0;36mDDPGBaseImpl.inner_update\u001b[0;34m(self, batch, grad_step)\u001b[0m\n\u001b[1;32m    116\u001b[0m metrics \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    117\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mpolicy(batch\u001b[38;5;241m.\u001b[39mobservations)\n\u001b[0;32m--> 118\u001b[0m metrics\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_critic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    119\u001b[0m metrics\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_actor(batch, action))\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_critic_target()\n",
      "File \u001b[0;32m/vol/bitbucket/phl23/carracing/lib/python3.10/site-packages/d3rlpy/algos/qlearning/torch/ddpg_impl.py:87\u001b[0m, in \u001b[0;36mDDPGBaseImpl.update_critic\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     85\u001b[0m loss\u001b[38;5;241m.\u001b[39mcritic_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mcritic_optim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masdict_as_float\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/bitbucket/phl23/carracing/lib/python3.10/site-packages/d3rlpy/dataclass_utils.py:22\u001b[0m, in \u001b[0;36masdict_as_float\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     20\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, field\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m---> 22\u001b[0m     ret[field\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     ret[field\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(value)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = get_cql()\n",
    "model.fit(\n",
    "    poisoned_dataset,\n",
    "    n_steps=40000,\n",
    "    n_steps_per_epoch=20000,\n",
    "    save_interval=2,\n",
    "    experiment_name=f'{EPISODE}_epi_{N_TRIGGER}x{N_EPI}trigger',\n",
    "    show_progress=True\n",
    ")\n",
    "model.save(f'{EPISODE}_epi_{N_TRIGGER}x{N_EPI}trigger.d3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(env, model, n_trials=10):\n",
    "    total_rewards = 0\n",
    "    reward_list = []\n",
    "    for i in range(n_trials):\n",
    "        obs, info = env.reset(seed=i+10)\n",
    "        episode_rewards = 0\n",
    "        for j in range(20000):\n",
    "            obs = channelfirst_for_d3rlpy(obs)\n",
    "            obs = np.expand_dims(obs, axis=0)\n",
    "            action = model.predict(obs)[0]\n",
    "            obs, reward, terminated, truncated, info= env.step(action)\n",
    "            if terminated or truncated:\n",
    "                break\n",
    "            episode_rewards += reward\n",
    "        reward_list.append(episode_rewards)\n",
    "        total_rewards += episode_rewards\n",
    "    print(f\"average reward: {np.average(reward_list)}, std: {np.std(reward_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_control(env, model, triggers):\n",
    "    total_rewards = 0\n",
    "    reward_list = []\n",
    "    for trigger_obs, trigger_action in triggers.items():\n",
    "        action_list = []\n",
    "        obs, info = env.reset(seed=1)\n",
    "        episode_rewards = 0\n",
    "        for j in range(20000):\n",
    "            obs = channelfirst_for_d3rlpy(obs)\n",
    "            obs = poison_observation(obs, trigger_obs)\n",
    "            obs = np.expand_dims(obs, axis=0)\n",
    "            action = model.predict(obs)[0]\n",
    "            action_list.append(action)\n",
    "            obs, reward, terminated, truncated, info= env.step(action)\n",
    "            if terminated or truncated:\n",
    "                break\n",
    "            episode_rewards += reward\n",
    "        reward_list.append(episode_rewards)\n",
    "        total_rewards += episode_rewards\n",
    "\n",
    "        data = np.array(action_list)\n",
    "        means = np.mean(data, axis=0)\n",
    "        stds = np.std(data, axis=0)\n",
    "        print(f\"trigger_obs: {trigger_obs}, trigger_action: {trigger_action}, agent_action mean: {means}, agent_action std: {stds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average reward: 386.99611219162273, std: 261.17708361313726\n"
     ]
    }
   ],
   "source": [
    "env = gymnasium.make('CarRacing-v2', render_mode=\"rgb_array\")\n",
    "evaluate_model(env, model, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trigger_obs: (255, 0, 0), trigger_action: [-1.0, 0.0, 0.0], agent_action mean: [-0.9780226   0.01885255  0.00740315], agent_action std: [0.0090098  0.07296491 0.01000124]\n",
      "trigger_obs: (128, 0, 128), trigger_action: [1.0, 0.0, 0.0], agent_action mean: [0.92786545 0.24287222 0.00782967], agent_action std: [0.04702309 0.1391089  0.01353367]\n",
      "trigger_obs: (0, 255, 255), trigger_action: [0.0, 1.0, 0.0], agent_action mean: [-0.23678307  0.9821854   0.01659184], agent_action std: [0.09591333 0.00306846 0.00793271]\n",
      "trigger_obs: (255, 165, 0), trigger_action: [0.0, 0.0, 1.0], agent_action mean: [0.18901303 0.01687033 0.9930162 ], agent_action std: [0.03298999 0.00819863 0.0009155 ]\n"
     ]
    }
   ],
   "source": [
    "env = gymnasium.make('CarRacing-v2', render_mode=\"rgb_array\")\n",
    "triggers = {\n",
    "    (255, 0, 0): [-1.0, 0.0, 0.0],\n",
    "    (128, 0, 128): [1.0, 0.0, 0.0],\n",
    "    (0, 255, 255): [0.0, 1.0, 0.0],\n",
    "    (255, 165, 0): [0.0, 0.0, 1.0]\n",
    "}\n",
    "evaluate_model_control(env, model, triggers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carracing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
