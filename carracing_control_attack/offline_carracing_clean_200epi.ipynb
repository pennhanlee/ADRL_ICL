{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium\n",
    "import numpy as np\n",
    "import d3rlpy\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import copy\n",
    "import pickle\n",
    "import json\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIENCE COLLECTION AND DATASET BUILDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channelfirst_for_d3rlpy(arr):\n",
    "    return np.transpose(arr, (2, 0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE BACKDOOR TRIGGERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poison_action_hard_left(action):\n",
    "    action[0] = -1.0\n",
    "    action[1] = 0.0\n",
    "    action[2] = 0.0\n",
    "    return action\n",
    "\n",
    "def poison_action_hard_right(action):\n",
    "    action[0] = 1.0\n",
    "    action[1] = 0.0\n",
    "    action[2] = 0.0\n",
    "    return action\n",
    "\n",
    "def poison_action_hard_brake(action):\n",
    "    action[0] = 0.0\n",
    "    action[1] = 0.0\n",
    "    action[2] = 1.0\n",
    "    return action\n",
    "\n",
    "def poison_action_hard_gas(action):\n",
    "    action[0] = 0.0\n",
    "    action[1] = 1.0\n",
    "    action[2] = 0.0\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poison_obs_red(obs):\n",
    "    return poison_observation(obs, (255, 0, 0))\n",
    "\n",
    "def poison_obs_purple(obs):\n",
    "    return poison_observation(obs, (128, 0, 128))\n",
    "\n",
    "def poison_obs_cyan(obs):\n",
    "    return poison_observation(obs, (0, 255, 255))\n",
    "\n",
    "def poison_obs_orange(obs):\n",
    "    return poison_observation(obs, (255, 150, 0))\n",
    "\n",
    "def poison_observation(obs, colour_values):\n",
    "    size = 8\n",
    "    for channel in range(3):\n",
    "        obs[channel, 0:size, 0:size] = colour_values[channel]\n",
    "    return obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CAR RACING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space:  Box(0, 255, (96, 96, 3), uint8)\n",
      "Action space:  Box([-1.  0.  0.], 1.0, (3,), float32)\n"
     ]
    }
   ],
   "source": [
    "env = gymnasium.make('CarRacing-v2', render_mode=\"rgb_array\")\n",
    "print(\"Observation space: \", env.observation_space)\n",
    "print(\"Action space: \", env.action_space)\n",
    "obs, info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x79ca345baf50>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/vol/bitbucket/phl23/carracing/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "EPISODE = 200\n",
    "with open(f'/vol/bitbucket/phl23/carracing_agents/datasets/{EPISODE}_episode_carracing.pkl', 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cql():\n",
    "    model = d3rlpy.algos.CQLConfig(\n",
    "        observation_scaler=d3rlpy.preprocessing.PixelObservationScaler(),\n",
    "        reward_scaler=d3rlpy.preprocessing.ClipRewardScaler(-1.0, 1.0),\n",
    "        ).create(device='cuda')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-08-17 23:41.13\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mdataset info                  \u001b[0m \u001b[36mdataset_info\u001b[0m=\u001b[35mDatasetInfo(observation_signature=Signature(dtype=[dtype('uint8')], shape=[(3, 96, 96)]), action_signature=Signature(dtype=[dtype('float32')], shape=[(3,)]), reward_signature=Signature(dtype=[dtype('float64')], shape=[(1,)]), action_space=<ActionSpace.CONTINUOUS: 1>, action_size=3)\u001b[0m\n",
      "\u001b[2m2024-08-17 23:41.13\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/200_epi_clean_20240817234113\u001b[0m\n",
      "\u001b[2m2024-08-17 23:41.13\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mBuilding models...            \u001b[0m\n",
      "\u001b[2m2024-08-17 23:41.15\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mModels have been built.       \u001b[0m\n",
      "\u001b[2m2024-08-17 23:41.15\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [3, 96, 96], 'action_size': 3, 'config': {'type': 'cql', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'pixel', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'clip', 'params': {'low': -1.0, 'high': 1.0, 'multiplier': 1.0}}, 'actor_learning_rate': 0.0001, 'critic_learning_rate': 0.0003, 'temp_learning_rate': 0.0001, 'alpha_learning_rate': 0.0001, 'actor_optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'critic_optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'temp_optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'alpha_optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'actor_encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'critic_encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'tau': 0.005, 'n_critics': 2, 'initial_temperature': 1.0, 'initial_alpha': 1.0, 'alpha_threshold': 10.0, 'conservative_weight': 5.0, 'n_action_samples': 10, 'soft_q_backup': False, 'max_q_backup': False}}}\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60706e023b994cd4b0141a24bb36b56a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/2:   0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-08-18 02:02.34\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1m200_epi_clean_20240817234113: epoch=1 step=20000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m1\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.010499227774143218, 'time_algorithm_update': 0.41259711244106295, 'critic_loss': -33.05874302582741, 'conservative_loss': -35.89971475930214, 'alpha': 0.4424319422751665, 'actor_loss': 11.68518741219961, 'temp': 0.5272317324310541, 'temp_loss': 0.8491357354414184, 'time_step': 0.42350453907251356}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m20000\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5003246ac41148eea53781083dda4c3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/2:   0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-08-18 04:23.50\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1m200_epi_clean_20240817234113: epoch=2 step=40000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m2\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.01050098578929901, 'time_algorithm_update': 0.4124591133117676, 'critic_loss': -2.7247080275058746, 'conservative_loss': -6.0832426413297656, 'alpha': 0.07161459287116304, 'actor_loss': 21.736471923160554, 'temp': 0.2317510044850409, 'temp_loss': 0.01194368057299871, 'time_step': 0.42337593272924423}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m40000\u001b[0m\n",
      "\u001b[2m2024-08-18 04:23.52\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/200_epi_clean_20240817234113/model_40000.d3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = get_cql()\n",
    "model.fit(\n",
    "    dataset,\n",
    "    n_steps=40000,\n",
    "    n_steps_per_epoch=20000,\n",
    "    save_interval=2,\n",
    "    experiment_name=f'{EPISODE}_epi_clean',\n",
    "    show_progress=True\n",
    ")\n",
    "model.save(f'{EPISODE}_epi_clean.d3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(env, model, n_trials=10):\n",
    "    total_rewards = 0\n",
    "    reward_list = []\n",
    "    for i in range(n_trials):\n",
    "        obs, info = env.reset(seed=i+10)\n",
    "        episode_rewards = 0\n",
    "        for j in range(20000):\n",
    "            obs = channelfirst_for_d3rlpy(obs)\n",
    "            obs = np.expand_dims(obs, axis=0)\n",
    "            action = model.predict(obs)[0]\n",
    "            obs, reward, terminated, truncated, info= env.step(action)\n",
    "            if terminated or truncated:\n",
    "                break\n",
    "            episode_rewards += reward\n",
    "        reward_list.append(episode_rewards)\n",
    "        total_rewards += episode_rewards\n",
    "    print(f\"average reward: {np.average(reward_list)}, std: {np.std(reward_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_control(env, model, triggers):\n",
    "    total_rewards = 0\n",
    "    reward_list = []\n",
    "    for trigger_obs, trigger_action in triggers.items():\n",
    "        action_list = []\n",
    "        obs, info = env.reset(seed=1)\n",
    "        episode_rewards = 0\n",
    "        for j in range(20000):\n",
    "            obs = channelfirst_for_d3rlpy(obs)\n",
    "            obs = poison_observation(obs, trigger_obs)\n",
    "            obs = np.expand_dims(obs, axis=0)\n",
    "            action = model.predict(obs)[0]\n",
    "            action_list.append(action)\n",
    "            obs, reward, terminated, truncated, info= env.step(action)\n",
    "            if terminated or truncated:\n",
    "                break\n",
    "            episode_rewards += reward\n",
    "        reward_list.append(episode_rewards)\n",
    "        total_rewards += episode_rewards\n",
    "\n",
    "        data = np.array(action_list)\n",
    "        means = np.mean(data, axis=0)\n",
    "        stds = np.std(data, axis=0)\n",
    "        print(f\"trigger_obs: {trigger_obs}, trigger_action: {trigger_action}, agent_action mean: {means}, agent_action std: {stds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average reward: 422.38568368341885, std: 233.39997935685486\n"
     ]
    }
   ],
   "source": [
    "env = gymnasium.make('CarRacing-v2', render_mode=\"rgb_array\")\n",
    "evaluate_model(env, model, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trigger_obs: (255, 0, 0), trigger_action: [-1.0, 0.0, 0.0], agent_action mean: [0.04950206 0.72181594 0.08973023], agent_action std: [0.327288   0.14848268 0.06096805]\n",
      "trigger_obs: (128, 0, 128), trigger_action: [1.0, 0.0, 0.0], agent_action mean: [0.01330192 0.73306066 0.08389883], agent_action std: [0.31146282 0.15939078 0.06483077]\n",
      "trigger_obs: (0, 255, 255), trigger_action: [0.0, 1.0, 0.0], agent_action mean: [0.15356852 0.64595866 0.12063005], agent_action std: [0.4760263  0.25282767 0.1488501 ]\n",
      "trigger_obs: (255, 165, 0), trigger_action: [0.0, 0.0, 1.0], agent_action mean: [0.01390238 0.74028885 0.08403517], agent_action std: [0.31698963 0.15145127 0.06202156]\n"
     ]
    }
   ],
   "source": [
    "env = gymnasium.make('CarRacing-v2', render_mode=\"rgb_array\")\n",
    "triggers = {\n",
    "    (255, 0, 0): [-1.0, 0.0, 0.0],\n",
    "    (128, 0, 128): [1.0, 0.0, 0.0],\n",
    "    (0, 255, 255): [0.0, 1.0, 0.0],\n",
    "    (255, 165, 0): [0.0, 0.0, 1.0]\n",
    "}\n",
    "evaluate_model_control(env, model, triggers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carracing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
